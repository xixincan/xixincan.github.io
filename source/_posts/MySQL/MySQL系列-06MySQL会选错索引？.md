---
title: MySQL系列--06MySQL会选错索引？
date: 2020-06-19 15:06:47
tags: 
- SQL
- MySQL
- MySQL系列
categories: MySQL 
keywords: MySQL,索引
cover: https://i.loli.net/2020/06/07/IJ6yCUvja8g9z7P.png
---
虽然前面已经详细整理了索引以及其相关的概念，但是索引对于我们来说，实在太常用到，而且时常会碰到SQL调优的场景。我们已经知道，MySQL里面一张表可以有多个索引，但是索引的选择却通常不是我们主动指定的，也就是说，具体使用不使用，使用哪个索引，由MySQL决定。当我知道MySQL有时也会选错索引导致执行速度很慢，我也很诧异，平常对索引的使用也没有太深追细节，所以，这篇整理我觉得也是很有必要的。探一探索引究竟是如何被选择，如果遇到选错了索引的情况，我们又该怎么处理。

从一个例子说起，代入感会更加明显，同时也能更清晰的说明问题。先建一张简单表t，有主键id、a、b三个字段，并分别建立索引，并使用存储过程向表t插入10万行递增的记录：
```sql
CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `a` int(11) DEFAULT NULL,
  `b` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `a` (`a`),
  KEY `b` (`b`)
) ENGINE=InnoDB;
```
```sql
delimiter ;;
create procedure idata()
begin
  declare i int;
  set i=1;
  while(i<=100000)do
    insert into t values(i, i, i);
    set i=i+1;
  end while;
end;;
delimiter ;
call idata();
```
初始化完毕后，我们分析这样一条SQL：
```sql
select * from t where a between 10000 and 20000;
```
很简单，a上有索引，使用的就是索引a，这点毋庸置疑。下图是explain命令查看这条SQL的执行情况：
![](https://static001.geekbang.org/resource/image/2c/e3/2cfce769551c6eac9bfbee0563d48fe3.png)
从上图来看确实符合预期，但是我们要搞点事情，让他变得复杂些。现在表t已经有了10万个数据了，再做如下的操作：

| 事务A | 事务B |
| :-: | :-: |
| start transaction with consistent snapshot;  |  |
|  | delete from t; |
|  | call idata(); |
|  | explain select * from t where a between 10000 and 20000; |
| commit; |  |

这时候事务B中的查询语句就不会再选择索引a了。通过慢查询日志（slow log）查看一下具体执行情况。为了说明优化器选择的结果是否正确，增加一个对照：让优化器强制使用索引a来对比。下面的三条SQL语句，就是这个实验过程。
```sql
set long_query_time=0;
select * from t where a between 10000 and 20000;                /*Q1*/
select * from t force index(a) where a between 10000 and 20000; /*Q2*/
```
第一句，是将慢查询日志的阈值设置为0，表示这个线程接下来的语句都会被记录入慢查询日志中;
第二句，Q1是事务B原来的查询；
第三句，Q2是加了force index(a)让优化器强制使用索引a来和Q1执行情况对比。
![](https://static001.geekbang.org/resource/image/7c/f6/7c58b9c71853b8bba1a8ad5e926de1f6.png)
可以看到，Q1扫描了10万行，显然是走了全表扫描，执行时间是40毫秒。Q2扫描了10001行，执行了21毫秒。也就是说，我们在没有使用force index的时候，MySQL用错了索引，导致了更长的执行时间。

### 优化器的逻辑
选择索引是优化器的工作，而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的CPU资源越少。当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。

我们这个简单的查询语句并没有涉及到临时表和排序，所以MySQL选错索引肯定是在判断扫描行数的时候出问题了。那**扫描行数是怎么判断的呢？**

MySQL在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好。我们可以使用**show index**方法，看到一个索引的基数。如下所示：
![](https://static001.geekbang.org/resource/image/16/d4/16dbf8124ad529fec0066950446079d4.png)
那么，**MySQL是怎样得到索引的基数的呢？** -- 采样统计。把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“采样统计”。

采样统计的时候，InnoDB默认会选择N个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过1/M的时候，会自动触发重新做一次索引统计。

在MySQL中，有两种存储索引统计的方式，可以通过设置参数innodb_stats_persistent的值来选择：
* 设置为on的时候，表示统计信息会持久化存储。这时，默认的N是20，M是10。
* 设置为off的时候，表示统计信息只存储在内存中。这时，默认的N是8，M是16。

由于是采样统计，所以不管N是20还是8，这个基数都是很容易不准的。但这还不是全部。从上图中看到，这次的索引统计值（cardinality列）虽然不够精确，但大体上还是差不多的，选错索引一定还有别的原因。

其实索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行。接下来，我们再一起看看优化器预估的，这两个语句的扫描行数是多少。
![](https://static001.geekbang.org/resource/image/e2/89/e2bc5f120858391d4accff05573e1289.png)
其中，rows这个字段表示的是预计扫描行数，Q1的结果还是符合预期的，rows的值是104620；但是Q2的rows值是37116，偏差就大了。最开始的explian命令看到的rows是只有10001行，是这个偏差误导了优化器的判断。

到这里，可能你的第一个疑问不是为什么不准，而是优化器为什么放着扫描37000行的执行计划不用，却选择了扫描行数是100000的执行计划呢？

这是因为，如果使用索引a，每次从索引a上拿到一个值，都要回到主键索引上查出整行数据，这个代价优化器也要算进去的。而如果选择扫描10万行，是直接在主键索引上扫描的，没有额外的代价。优化器会估算这两个选择的代价，从结果看来，优化器认为直接扫描主键索引更快。当然，从执行时间看来，这个选择并不是最优的。

所以MySQL选错索引，这件事儿还得归咎到没能准确地判断出扫描行数。既然是统计信息不对，那就修正。**analyze table t **命令，可以用来重新统计索引信息。我们来看一下执行效果。
![](https://static001.geekbang.org/resource/image/20/9c/209e9d3514688a3bcabbb75e54e1e49c.png)
这回对了。所以在实践中，如果你发现explain的结果预估的rows值跟实际情况差距比较大，可以采用这个方法来处理。

如果只是索引统计不准确，通过analyze命令可以解决很多问题，但是前面我们说了，优化器可不止是看扫描行数。依然是基于这个表t，我们看看另外一个语句：
```sql
select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 1;
```
从条件上看，这个查询没有符合条件的记录，因此会返回空集合。在开始执行这条语句之前，你可以先设想一下，如果你来选择索引，会选择哪一个呢？
* 如果使用索引a进行查询，那么就是扫描索引a的前1000个值，然后取到对应的id，再到主键索引上去查出每一行，然后根据字段b来过滤。显然这样需要扫描1000行。
* 如果使用索引b进行查询，那么就是扫描索引b的最后50001个值，与上面的执行过程相同，也是需要回到主键索引上取值再判断，所以需要扫描50001行。

如果使用索引a的话，执行速度明显会快很多。那么，下面我们就再用eplain命令来看看到底是不是这样。
![](https://static001.geekbang.org/resource/image/48/b8/483bcb1ef3bb902844e80d9cbdd73ab8.png)
可以看到，返回结果中key字段显示，这次优化器选择了索引b，而rows字段显示需要扫描的行数是50198。扫描行数的估计值依然不准确，MySQL又选错了索引。

### 索引选择异常和处理
其实大多数时候优化器都能找到正确的索引，但偶尔你还是会碰到我们上面举例的这两种情况。原本可以执行得很快的SQL语句，执行速度却比你预期的慢很多，应该怎么办呢？
#### force index
**采用force index强行选择一个索引。**MySQL会根据词法解析的结果分析出可能可以使用的索引作为候选项，然后在候选列表中依次判断每个索引需要扫描多少行。如果force index指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。

来看下上面SQL采用force index的效果：
![](https://static001.geekbang.org/resource/image/95/54/9582401a6bed6cb8fd803c9555750b54.png)
可以看到，原本语句需要执行2.23秒，而当你使用force index(a)的时候，只用了0.05秒，比优化器的选择快了40多倍。也就是说，优化器没有选择正确的索引，force index起到了“矫正”的作用。

但是这种方法是有明显缺点的，一来这么写不优美，二来如果索引改了名字，这个语句也得改。而且如果以后迁移到别的数据库的话，这个语法还可能会不兼容。

#### 优化SQL
既然优化器放弃了使用索引a，说明a还不够合适，所以第二种方法就是，我们可以**考虑修改语句，引导MySQL使用我们期望的索引**。

比如，在这个例子里，显然把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。
![](https://static001.geekbang.org/resource/image/14/94/14cd598e52a2b72dd334a42603e5b894.png)
之前优化器选择使用索引b，是因为它认为使用索引b可以避免排序（b本身是索引，已经是有序的了，如果选择索引b的话，不需要再做排序，只需要遍历），所以即使扫描行数多，也判定为代价更小。

现在order by b,a 这种写法，要求按照b,a排序，就意味着使用这两个索引都需要排序。因此，扫描行数成了影响决策的主要条件，于是此时优化器选了只需要扫描1000行的索引a。

**但是这种修改并不通用**。只是刚好在这个语句里面有limit 1，因此如果有满足条件的记录， order by b limit 1和order by b,a limit 1 都会返回b是最小的那一行，逻辑上一致，才可以这么做。所以这种方法的缺点就是一来通用性低，二来很容易修改了原来的语义导致结果偏差。

#### 另起炉灶
第三种方法是，在有些场景下，我们可以**新建一个更合适的索引**，来提供给优化器做选择，**或删掉误用的索引**。这种方法也有缺点，情况太少见，找一个更合适的索引一般比较困难。 

### 小结
本篇主要整理了索引统计的更新机制，并提到了优化器存在选错索引的可能性。

对于由于索引统计信息不准确导致的问题，你可以用analyze table来解决。

而对于其他优化器误判的情况，你可以在应用端用force index来强行指定索引，也可以通过修改语句来引导优化器，还可以通过增加或者删除索引来绕过这个问题。